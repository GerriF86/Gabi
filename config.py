# config.py

# Any local Ollama model or LLM config you may want.
SETTINGS = {
    "model": "llama3.2:3b",
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40
}
